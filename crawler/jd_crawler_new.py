# jd_crawler_new.py
from DrissionPage import ChromiumPage, ChromiumOptions
import time
import re
from typing import List, Optional

class JDPriceCrawlerRunner:
    """äº¬ä¸œä»·æ ¼çˆ¬è™«è¿è¡Œå™¨ï¼ˆæé€Ÿç‰ˆï¼šæ— æ»šåŠ¨+çŸ­ç­‰å¾…ï¼‰"""
    
    DEFAULT_CONFIG = {
        "keyword": "ä½³èƒ½80dæœºèº«",
        "min_price": 1000,
        "max_price": 20000,
        "max_price_count": 30,
        "browser_data_dir": "F:\\jd\\browser_data",
        "headless": False
    }

    def __init__(self, config: Optional[dict] = None):
        self.config = {**self.DEFAULT_CONFIG, **(config or {})}
        self.browser: Optional[ChromiumPage] = None
        self.filtered_prices: List[float] = []
        
        # æå–é…ç½®
        self.keyword = self.config["keyword"]
        self.min_price = self.config["min_price"]
        self.max_price = self.config["max_price"]
        self.max_price_count = self.config["max_price_count"]
        self.browser_data_dir = self.config["browser_data_dir"]
        self.headless = self.config["headless"]

    def _init_browser(self) -> ChromiumPage:
        """åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆç¦ç”¨ç¼“å­˜ï¼‰"""
        if self.browser and self.browser.connected:
            return self.browser
        
        co = ChromiumOptions()
        # åçˆ¬+é˜²ç¼“å­˜é…ç½®
        co.set_argument('--disable-blink-features=AutomationControlled')
        co.set_argument('--ignore-certificate-errors')
        co.set_argument(f'--user-data-dir={self.browser_data_dir}')
        # UAé…ç½®
        co.set_user_agent(
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )
        co.headless(self.headless)
        
        self.browser = ChromiumPage(co)
        return self.browser

    def manual_login(self) -> None:
        """æ‰‹åŠ¨ç™»å½•äº¬ä¸œ"""
        self._init_browser()
        print("ğŸ” è¯·åœ¨æµè§ˆå™¨å®Œæˆäº¬ä¸œç™»å½•åæŒ‰å›è½¦...")
        self.browser.get('https://www.jd.com')
        input("âœ… ç™»å½•å®Œæˆ â†’ æŒ‰å›è½¦é”®ç»§ç»­")
        print("ğŸ“Œ ç™»å½•çŠ¶æ€å·²ä¿å­˜ï¼Œåç»­è¿è¡Œæ— éœ€é‡å¤ç™»å½•")

    def _extract_price_from_item(self, item) -> Optional[float]:
        """ä»å•ä¸ªå•†å“å…ƒç´ æå–ä»·æ ¼"""
        try:
            # ä¼˜å…ˆæå–data-priceå±æ€§
            price_attr = item.attr('data-price') or item.ele('.p-price').attr('data-price')
            if price_attr and price_attr.replace('.', '').isdigit():
                return float(price_attr)
            return None
        except (ValueError, AttributeError, TypeError):
            return None

    def _extract_prices(self) -> List[float]:
        """æå–ä»·æ ¼ï¼ˆæ— æ»šåŠ¨+çŸ­ç­‰å¾…+é¦–å±ä¼˜å…ˆï¼‰"""
        valid_prices = []
        
        # 1. æ„é€ URL+è½»é‡åˆ·æ–°
        search_url = f"https://search.jd.com/Search?keyword={self.keyword}&enc=utf8&t={int(time.time())}"
        self.browser.get(search_url)
        print(f"â³ æ­£åœ¨åŠ è½½ã€{self.keyword}ã€‘äº¬ä¸œæœç´¢ç»“æœ...")
        time.sleep(4)  
        
        # 2. ç›´æ¥æå–é¦–å±å•†å“
        product_items = self.browser.eles('div.gl-item')
        print(f"ğŸ” æ‰¾åˆ° {len(product_items)} ä¸ªé¦–å±å•†å“ï¼Œå¼€å§‹æå–ä»·æ ¼...")
        
        # 3. æé€Ÿæå–ä»·æ ¼ï¼ˆåªå–å‰30ä¸ªç¬¦åˆæ¡ä»¶çš„ï¼‰
        for item in product_items:
            if len(valid_prices) >= self.max_price_count:
                break
            price = self._extract_price_from_item(item)
            if price and self.min_price <= price <= self.max_price:
                valid_prices.append(price)
        
        # å…œåº•ï¼šå¦‚æœé¦–å±ä¸å¤Ÿï¼Œæç®€å…¨å±€åŒ¹é…
        if not valid_prices:
            page_source = self.browser.html
            price_pattern = re.compile(r'Â¥\s*(\d+(?:\.\d+)?)')
            all_price_str = price_pattern.findall(page_source)[:self.max_price_count]
            valid_prices = [float(p) for p in all_price_str if self.min_price <= float(p) <= self.max_price]
        
        # å»é‡+é™åˆ¶æ•°é‡
        valid_prices = list(dict.fromkeys(valid_prices))[:self.max_price_count]
        return valid_prices

    def run(self, need_login: bool = True) -> List[float]:
        """è¿è¡Œçˆ¬è™«ï¼ˆæé€Ÿç‰ˆï¼‰"""
        try:
            if need_login:
                self.manual_login()
            else:
                self._init_browser()
            
            self.filtered_prices = []
            self.filtered_prices = self._extract_prices()
            return self.filtered_prices
        
        except Exception as e:
            print(f"âŒ äº¬ä¸œçˆ¬è™«è¿è¡Œå‡ºé”™ï¼š{str(e)}")
            raise

# ===================== å…³é”®ï¼šæ·»åŠ ä¾›å¤–éƒ¨è°ƒç”¨çš„å‡½æ•° =====================
def get_jd_prices_simple(keyword, min_price=1000, max_price=20000, max_count=30, need_login=False):
    """
    äº¬ä¸œä»·æ ¼æå–ç®€åŒ–å‡½æ•°ï¼ˆä¾› crawler_runner.py è°ƒç”¨ï¼‰
    :param keyword: æœç´¢å…³é”®è¯
    :param min_price: æœ€ä½ä»·æ ¼
    :param max_price: æœ€é«˜ä»·æ ¼
    :param max_count: æœ€å¤šæå–æ•°é‡
    :param need_login: æ˜¯å¦éœ€è¦ç™»å½•
    :return: ä»·æ ¼åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œå…¼å®¹åŸå§‹è°ƒç”¨é€»è¾‘ï¼‰
    """
    config = {
        "keyword": keyword,
        "min_price": min_price,
        "max_price": max_price,
        "max_price_count": max_count
    }
    crawler = JDPriceCrawlerRunner(config)
    prices = crawler.run(need_login=need_login)
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
    return [str(p) for p in prices]

# ------------------- æµ‹è¯•å…¥å£ï¼ˆå¯é€‰ï¼‰ -------------------
if __name__ == "__main__":
    # æµ‹è¯•å‡½æ•°è°ƒç”¨
    test_prices = get_jd_prices_simple("ç´¢å°¼a7m4æœºèº«", 5000, 15000, 30, False)
    print("æµ‹è¯•æå–çš„ä»·æ ¼ï¼š", test_prices)